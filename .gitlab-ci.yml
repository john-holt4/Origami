# 1. We only need two stages now
stages:
  - build   # Build container and push to registry
  - iso     # Pull container, generate ISO, and upload to S3

workflow:
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS && $CI_PIPELINE_SOURCE == "push"
      when: never
    - if: "$CI_COMMIT_TAG"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: "$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS"
      when: never
    - if: "$CI_COMMIT_BRANCH"

.bluebuild-job-template:
  tags:
    - saas-linux-2xlarge-amd64
  image:
    name: ghcr.io/blue-build/cli
    entrypoint: [""]
  services:
    - docker:dind
  parallel:
    matrix:
      - RECIPE: "recipe-base.yml"
        ISO_NAME: "origami-x86_64.iso"
        IMAGE_NAME: "registry.gitlab.com/origami-linux/images/origami"
      - RECIPE: "recipe-nvidia.yml"
        ISO_NAME: "origami-nvidia-x86_64.iso"
        IMAGE_NAME: "registry.gitlab.com/origami-linux/images/origami-nvidia"
  variables:
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: /certs
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: $DOCKER_TLS_CERTDIR/client
    # Set the S3 endpoint URL for Cloudflare R2
    S3_ENDPOINT_URL: "https://0041560ce1f22c78111d98dfde401cac.r2.cloudflarestorage.com"
  before_script:
    - curl --silent "https://gitlab.com/gitlab-org/incubation-engineering/mobile-devops/download-secure-files/-/raw/main/installer" | bash
    - export COSIGN_PRIVATE_KEY=$(cat .secure_files/cosign.key)
    # Log in to the GitLab registry
    - echo "Logging in to $CI_REGISTRY..."
    - echo $CI_REGISTRY_PASSWORD | docker login $CI_REGISTRY -u $CI_REGISTRY_USER --password-stdin
    - sleep 5

build-image:
  extends: .bluebuild-job-template
  stage: build
  script:
    - bluebuild build --verbose --rechunk --push ./recipes/$RECIPE

# 2. This is the new, combined job
generate_and_upload_iso:
  extends: .bluebuild-job-template
  stage: iso
  before_script:
    # We run the template's before_script first
    - !reference [.bluebuild-job-template, before_script]
    
    # 3. Now we install the aws-cli in the bluebuild container
    - echo "Installing AWS CLI..."
    # The bluebuild image is Fedora-based, so we must install 'unzip' first
    - dnf install -y unzip
    - curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
    - unzip awscliv2.zip
    - ./aws/install
    - echo "AWS CLI installed."
    
  script:
    # 4. First, generate the ISO
    - echo "Generating $ISO_NAME from image $IMAGE_NAME..."
    - bluebuild generate-iso --web-ui --iso-name $ISO_NAME image $IMAGE_NAME
    
    # 5. Second, upload it (if the build succeeded)
    - echo "Uploading $ISO_NAME to $S3_ENDPOINT_URL"
    - export AWS_ACCESS_KEY_ID=$S3_ACCESS_KEY
    - export AWS_SECRET_ACCESS_KEY=$S3_SECRET_KEY
    - |
      aws s3 cp $ISO_NAME s3://origami-linux/$ISO_NAME \
        --endpoint-url $S3_ENDPOINT_URL
        